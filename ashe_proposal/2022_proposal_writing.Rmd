---
title: Employing Machine-Learning Approaches in Predicting Incomes of Recent College Graduates
author: "Will Doyle, Benjamin Skinner, Olivia Morales"
subtitle: Proposal for ASHE 2022
output: pdf_document
bibliography: csc_research.bib
csl: apa.csl
---

```{r setup, echo=F, include=F, message=F, warning=F, error=F}

library(knitr)
library(tidyverse)
library(haven)
library(bibtex)
library(ggridges)
library(scales)
library(here)
library(janitor)
library(rmarkdown)

knitr::opts_chunk$set(echo = FALSE,warning = FALSE,include=TRUE,message = FALSE,fig.width=10,fig.height = 10)

```

```{r}
cb_df<-read_rds(here("data","cleaned","cb_df.Rds"))
```

## Abstract  


This project explores the capabilities of institutional variables in predicting  recent college graduates' earnings via machine-learning approaches. Precursory results support the predictive capabilities of expected institutional characteristics like school classification, while illuminating unexpected predictors like overall debt repayment rates on recent graduate earnings.


\newpage

## Objective/Background

| The creation and publication of the College Scorecard by the U.S. Department of Education derived from President Obama's frustration with lack of institutional transparency as to rising costs and ultimate goal to increase college affordability and grow the U.S. middle class [@obama_2013]. The College Scorecard presented an opportunity for families to identify the institutions that provided the best outcomes for their students with the least amount of financial burden. Made publicly available in 2015, the data in the College Scorecard (while rich and vast in information), did not generally produce the kind of impact the Obama administration envisioned. In @hurwitz_student_2018, results indicated decision-making changes in generally well-resourced high school students after the publication of the Scorecard, directing their SAT scores to schools that, on average, had higher median earnings for graduates; the two other hallmarks of the Scorecard (graduation rates and average costs), produced virtually no change in SAT score-sending behaviors.
|       Accompanied with the less than promising results from @huntington-klein_search_2017 on the impact of the College Scorecard release on subsequent college Google search activity, the Scorecard put forward a wealth of data that were simultaneously underutilized by the target demographic and generally underemployed by higher education researchers. While literature does exist engaging the earnings data and available on the Scorecard in particular institutional & program contexts [@boland_effect_2021; @elu_earnings_2019; @mabel_value_2020; @seaman_assessing_2017], the Scorecard is largely missing from literature and general higher education discourse on college affordability and broadening college access.
|       Machine learning, as an academic field of study, shares much in common with the vastly growing discipline marrying both statistical methods and computer science. While commonly associated with convoluted computational statistics and computer programming methods, it has crept into the education (particularly higher education) field to increase model accuracy and potential estimates in quantitative higher education studies. In particular, the last 6-7 years have seen an uptick in higher education research projects utilizing machine learning methods [@aulck2017predicting; @savvas_etal_2021; @Zeineddine_2021].With this increase in prominence, how does this project stand out?
|       This project fills a dire gap in higher education literature by not only utilizing the myriad institutional data points available on the Scorecard, but marrying these data with novel machine learning techniques that improve the predictive capacity of common institutional characteristics.

## Methodology

| Our methodology is defined by machine-learning approaches to data analysis, characterized by the use of a model workflow, feature engineering for model use and elastic net/random forest regression models to appropriately fit our data and identify potential income predictors.
|     More specifically, we first read in the College Scorecard data (the field of study and all data elements files, specifically) and performed necessary preprocessing work to 1) drop data that were privacy suppressed/missing, 2) recode categorical data to workable dummy-coded variables and 3) drop zero variance/highly correlated predictors. 
|     Next, we performed kfold cross validation (20 folds) on the training set data to set the foundation for model selection/evaluation. Two regression-based methods (elastic net and random forest) were then identified to build subsequent models, add models to built workflow and fit the models to resampled data. Model tuning was then performed for both models to ensure maximum predictive capacity. Elastic net regularization is an improved version of the LASSO method that combines penalties to remove non-predictive coefficients. Random forest regression produce variable cases and forces a vote on the most likely outcome for the covariate in question.
|     These methods resulted in predictive estimates for both the elastic net and random forest regression models critical to our ultimate analyses/findings. These predictors are variables identified in the Scorecard dataset that are highly predictive indicators of our dependent variable: median earnings from graduates of the program after 1 year.

## Data 

| Data for this project originate from two specific sources: the College Scorecard and the most recent American Community Survey 5-year estimates (2016-2020), selecting 2019 data to align with the recent 2019-20 school year data featured in the Scorecard. The Scorecard provided us with our dependent variable data (median earnings for college graduates 1 year after graduation), and accompanied with the ACS county-level data, contributes the numerous possible predictors for our models.
|     More specifically, the ACS county data feature FIPS codes to uniquely identify each county, calculations for: 1) the percentage of county bachelor's degree holders, 2) the percentage of homeowners in each county and 3) the percentage of individuals identified in the county labor force and the median household income for each county (for most recent 12 months, using 2019-adjusted dollars). The College Scorecard data present 2,000+ variables regarding institutional characteristics and program-level data for 6,700 accredited institutions in the U.S., including type of institution, degrees awarded, number of loan borrowers and the like. FIPS codes are also featured in this data set, allowing for appropriate matching of institutions to their location in each county first identified by the ACS data. Much of the Scorecard data based in more specific, individual student information were suppressed for privacy reasons.

## Preliminary Findings

| In our first 3 figures, we delineate the median first year earnings of different degree holders (Bachelors, Associates and Certificates/Diplomas). In looking at this figures descriptively, there seems to be an increase in earnings potential for Bachelors degree holders as compared to Associates/Certificate degree holders in similar fields of study. However, this conclusion necessitates further analyses to determine the predictive capabilities of things other than field of study (institutional characteristics, student traits, etc.) in determining the incomes of recent college graduates.
|     Both the elastic net and random forest regression models produced estimates to inform the predictive capabilities of certain program/institutional characteristics. Figure 4 demonstrates those estimates from elastic net, identifying typically assumed positive predictors of income like type of school, type of degree/credential; however, this model also illuminated particularly unexpected predictors like outstanding Federal loan balance and median debt for graduated students.
|   In our random forest regression model (Figure 5), we see a similar emphasis on the importance of type of degree credential (specifically Certificates/Diplomas and Bachelors Degrees); we also see the importance of median family income and average family income for those students considered independents (both income values in real 2015 dollars). Unexpected, however, were the appearances of 3-year cohort default rates and the percentage of students who completed their coursework within 8 years at the original institution (Satisfactory Academic Progress). 

## Study Significance

| While the technical nature of machine learning approaches can seem far removed from the higher education policy landscape at large, this study, at its foundation, cares about the material outcomes for students investing their money and time in their educational futures. More specifically, we are preoccupied with identifying the greatest predictors of college graduates' incomes to ultimately inform good policy & practice that amplifies positive student earnings potential.
|   Machine learning approaches hold incredible posibilities in providing the most accurate estimates of the data points we as higher education practitioners/researchers care so deeply about: student outcomes. It is evident that the integration of machine learning into higher education research methods/practice has already begun, and this project adds to this movement and solidifies its place in the higher education policy landscape. 


\newpage

```{r}
cb_df<-read_rds(here("data","cleaned","cb_df.Rds"))
```

# Figures

## Figure 1 

### First Year Earnings of Bachelor's Degree Holders

```{r}
cb_df%>%
  group_by(cipdesc,creddesc)%>%
  select(earn_mdn_hi_1yr,creddesc,cipdesc)%>%
  mutate(count=n())%>%
  filter(count>20)%>%
  mutate(mean_earn=mean(earn_mdn_hi_1yr,na.rm=TRUE))%>%
  group_by(creddesc)%>%
  arrange(creddesc,desc(mean_earn)) %>% 
  mutate(earn_rank=rank(-mean_earn))%>%
  filter(earn_rank<2000)%>%
  filter(creddesc=="Bachelors Degree")%>%
  ggplot(aes(x=earn_mdn_hi_1yr,
             y=fct_reorder(cipdesc,.x=mean_earn),fill=cipdesc))+
  geom_density_ridges()+
  theme_minimal()+
  theme(legend.position = "none")+
  ylab("")+
  xlab("")+
  scale_x_continuous(labels=dollar_format())
```

\newpage

## Figure 2

### First Year Earnings of Associate Degree Holders
```{r}
cb_df%>%
  group_by(cipdesc,creddesc)%>%
  select(earn_mdn_hi_1yr,creddesc,cipdesc)%>%
  mutate(count=n())%>%
  filter(count>20)%>%
  mutate(mean_earn=mean(earn_mdn_hi_1yr,na.rm=TRUE))%>%
  group_by(creddesc)%>%
  arrange(creddesc,desc(mean_earn)) %>% 
  mutate(earn_rank=rank(-mean_earn))%>%
  filter(earn_rank<2000)%>%
  filter(creddesc=="Associate's Degree")%>%
  ggplot(aes(x=earn_mdn_hi_1yr,
             y=fct_reorder(cipdesc,.x=mean_earn),fill=cipdesc))+
  geom_density_ridges()+
  theme_minimal()+
  theme(legend.position = "none")+
  ylab("")+
  xlab("")+
  scale_x_continuous(labels=dollar_format())
```
\newpage

## Figure 3

### First Year Earnings of Certificate Holders
```{r}
cb_df%>%
  group_by(cipdesc,creddesc)%>%
  select(earn_mdn_hi_1yr,creddesc,cipdesc)%>%
  mutate(count=n())%>%
  filter(count>20)%>%
  mutate(mean_earn=mean(earn_mdn_hi_1yr,na.rm=TRUE))%>%
  group_by(creddesc)%>%
  arrange(creddesc,desc(mean_earn)) %>% 
  mutate(earn_rank=rank(-mean_earn))%>%
  filter(earn_rank<2000)%>%
  filter(creddesc=="Undergraduate Certificate or Diploma")%>%
  ggplot(aes(x=earn_mdn_hi_1yr,
             y=fct_reorder(cipdesc,.x=mean_earn),fill=cipdesc))+
  geom_density_ridges()+
  theme_minimal()+
  theme(legend.position = "none")+
  ylab("")+
  xlab("")+
  scale_x_continuous(labels=dollar_format())
```

\newpage

## Figure 4 

### Elastic Net Estimates


```{r}

load("../scripts/enet_vi.Rdata")

gg
```



\newpage


## Figure 5

### Random Forest Regression: Variable Importance

![](../figures/rf_vi.png)