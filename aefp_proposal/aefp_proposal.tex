\thispagestyle{empty}
\newpage

\hypertarget{objectivebackground}{%
\section{Objective/Background}\label{objectivebackground}}

The publication of the College Scorecard in 2015 presented an
opportunity for families to identify institutions that provided the best
labor outcomes with the least amount of financial burden for students
{[}@obama\_2013{]}. Though ostensibly underutilized by consumers
{[}@huntington2016search{]}, @hurwitz\_student\_2018 show how students'
college decision-making changed after the Scorecard's initial release,
finding that students directed their SAT scores to schools with higher
median earnings for graduates. This signals the continued salience of
future earnings potential for students who are deciding on colleges and
degree programs {[}@berger\_1988, @wiswallzafar\_2015{]}.

As future earnings potential universally informs student college/program
choices, it's important to consider how researchers can make
increasingly data-driven earnings predictions {[}@Imbens\_2004{]}.
Compared to the standard econometric toolkit, approaches based in data
science and machine learning can improve estimate quality by following
structured procedures and computational algorithms to build, test, and
train statistical models {[}@Hastie\_etal\_2016{]}.

In this project, we use machine learning methods and common
institutional/program variables in the College Scorecard to provide
robust predictions of program earnings for recent college graduates.
This work supports future higher education research in two key ways.
First, we offer an example of a principled approach to model
specification based in data science procedure that we believe could be
more widely incorporated in higher education policy research
{[}@Kuhn\_Silge\_2022{]}. Second, we take full advantage of these tools
to fit a large number of institutional data points available through the
College Scorecard, increasing the predictive capacity of our models in
determining program-level earnings.

Our goal is to provide more accurate earnings predictions that will
support the mission of policymakers in growing overall students'
earnings potential.

\hypertarget{research-questions}{%
\section{Research Questions}\label{research-questions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What institutional/program level variables are most predictive of
  median first-year earnings?
\item
  What are the patterns of association (positive/negative) for these
  variables?
\end{enumerate}

\hypertarget{data}{%
\section{Data}\label{data}}

Data for this project originate from the College Scorecard and the
American Community Survey. In addition to our key outcome variable of
interest, median earnings for college graduates one year after
graduation, we take advantage of the large number of variables available
in the College Scorecard data set. These include over 2,000 variables
featuring institutional characteristics and program-level data for 6,700
accredited institutions in the U.S. Using county FIPS codes, we match
each higher education institution with county-level data from the ACS.
The ACS allows us to recover contextual information lost in the
Scorecard due to privacy suppression.

\hypertarget{methodology}{%
\section{Methodology}\label{methodology}}

Our process begins with reading in the full College Scorecard data set,
which includes program-specific data elements. Using the Tidy models
framework {[}@Kuhn\_Silge\_2022{]}, we perform a pipeline of
preprocessing work that includes (1) dropping privacy suppressed/missing
data elements, (2) recoding categorical data to dummy-coded indicator
variables, and (3) removing zero variance/highly correlated predictors.

Next, we partition our data into two sets: a training data set which we
use for model building and a testing data set that we use to produce our
results. As part of the model construction process, we perform k-fold
cross validation on the training set data. Specifically, we recursively
split the training data into 20 separate data sets, fitting and tuning
the best model each time and then averaging across all results. After
deciding upon the best model, we use it to predict program-level
earnings using the held-out testing data to mitigate issues of
overfitting the data.

For our models, we use two regression-based, machine-learning methods:
elastic net and random forest. Elastic net regularization combines LASSO
and ridge regression penalties to remove non-predictive coefficients
from the model. Random forest regression models average results from a
large number of decision trees fit to a random subset of observations
and covariates {[}@Hastie\_etal\_2016{]}. These models are particularly
useful in our project, as they provide two key benefits. First, they
offer principled predictor selection from a large set of possible
determinants of earnings. Second, they support the identification of
non-linear relationships between predictors, which means our predictions
are not dependent on a researcher-established functional form in the
model. Using these two modeling approaches we identify variables in the
Scorecard data that are highly predictive indicators of our dependent
variable of interest: median earnings from program graduates after one
year.

\hypertarget{preliminary-findings}{%
\section{Preliminary Findings}\label{preliminary-findings}}

Across figures 1-3 (please see uploaded files for our figures), we show
median first year earnings for a selection of programs at three degree
levels: Bachelor's, Associate and Certificate/Diploma. Across the
figures, we see generally greater earnings potential for Bachelors
degree holders compared to other degree holders in similar fields of
study. For example, those who earn a Bachelor's degree in computer
programming earn just over \$50,000 in their first year compared to
computer programmers with an associate degree or those with a
certificate in computer systems networking and telecommunications who
earn closer to \$30,000.

Figure 4 shows predictor estimates from the elastic net model (see Table
1 for a concordance of variable names with their descriptions). The
length of the bars represent the predictive power of the variable, with
the color of the bars representing the direction of the association
between predictor and outcome. While we identify some variables
typically assumed to be positive predictors of graduate income like type
of school, type of degree/credential, we also find some unexpected
positive and negative predictors of first year earnings, like
outstanding federal loan balance and median debt for graduated students.

Figure 5 shows the most important variables (those most predictive) of
median first year earnings from our random forest regression model. As
with our elastic net model results, we see a similar emphasis on the
importance of type of degree credential, specifically
certificate/diploma and Bachelor's degrees. We also see the importance
of median family income and average family income for independent
students. Less expected are the comparative importance---compared to
many thousand predictors---of three-year cohort default rates and the
percentage of students making satisfactory academic progress in
predicting student earnings.

\hypertarget{references}{%
\section{References}\label{references}}
